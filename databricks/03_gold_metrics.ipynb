{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü•á Gold Layer ‚Äî Business Metrics\n",
                "\n",
                "**Annie's Magic Numbers Medallion Architecture**\n",
                "\n",
                "This notebook produces analytical tables for Power BI using clean Silver data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîê Configuration ‚Äî ADLS Gen2 Authentication"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "spark.conf.set(\n",
                "    \"fs.azure.account.key.anniedatalake123.dfs.core.windows.net\",\n",
                "    \"<PASTE_STORAGE_ACCOUNT_KEY_1_HERE>\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¶ Path Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import functions as F\n",
                "from pyspark.sql.window import Window\n",
                "\n",
                "container_name = \"annie-data\"\n",
                "storage_account = \"anniedatalake123\"\n",
                "\n",
                "base_path = f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/\"\n",
                "silver_path = base_path + \"silver/\"\n",
                "gold_path = base_path + \"gold/\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¶ Register Silver Tables as Temporary Views"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "spark.read.format(\"delta\").load(silver_path + \"sales\").createOrReplaceTempView(\"sv_sales\")\n",
                "spark.read.format(\"delta\").load(silver_path + \"purchases\").createOrReplaceTempView(\"sv_purchases\")\n",
                "spark.read.format(\"delta\").load(silver_path + \"beg_inventory\").createOrReplaceTempView(\"sv_beg_inv\")\n",
                "spark.read.format(\"delta\").load(silver_path + \"end_inventory\").createOrReplaceTempView(\"sv_end_inv\")\n",
                "\n",
                "print(\"‚úÖ  Temporary views registered from Silver paths.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¶ Helper Writer Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def write_gold(df, table_name, partition_by=None):\n",
                "    writer = (\n",
                "        df.write\n",
                "          .format(\"delta\")\n",
                "          .mode(\"overwrite\")\n",
                "          .option(\"overwriteSchema\", \"true\")\n",
                "    )\n",
                "    if partition_by:\n",
                "        writer = writer.partitionBy(partition_by)\n",
                "    \n",
                "    target_path = gold_path + table_name\n",
                "    writer.save(target_path)\n",
                "    \n",
                "    count = spark.read.format(\"delta\").load(target_path).count()\n",
                "    print(f\"   ‚úÖ  gold.{table_name} saved to {target_path}  ‚Üí  {count:,} rows\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü•á Gold ‚Äî Core Cost Lookup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cost_lookup = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        brand,\n",
                "        description,\n",
                "        PERCENTILE_APPROX(cost_per_unit, 0.5)  AS median_cost_per_unit,\n",
                "        AVG(cost_per_unit)                       AS avg_cost_per_unit\n",
                "    FROM sv_purchases\n",
                "    WHERE cost_per_unit IS NOT NULL AND cost_per_unit > 0\n",
                "    GROUP BY brand, description\n",
                "\"\"\")\n",
                "cost_lookup.createOrReplaceTempView(\"cost_lookup\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü•á Gold ‚Äî Sales Enriched"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sales_enriched = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        s.*,\n",
                "        COALESCE(c.median_cost_per_unit, s.sales_price * 0.60) AS cost_per_unit,\n",
                "        ROUND(s.sales_dollars - (COALESCE(c.median_cost_per_unit, s.sales_price * 0.60) * s.sales_quantity), 2) AS profit_dollars,\n",
                "        ROUND(CASE WHEN s.sales_dollars = 0 THEN NULL \n",
                "              ELSE ((s.sales_dollars - COALESCE(c.median_cost_per_unit, s.sales_price * 0.60) * s.sales_quantity) / s.sales_dollars) * 100 \n",
                "              END, 2) AS margin_pct\n",
                "    FROM sv_sales s\n",
                "    LEFT JOIN cost_lookup c ON s.brand = c.brand AND s.description = c.description\n",
                "\"\"\")\n",
                "sales_enriched.createOrReplaceTempView(\"gold_se\")\n",
                "write_gold(sales_enriched, \"sales_enriched\", partition_by=\"brand\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü•á Gold ‚Äî Product & Brand Profitability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "product_profitability = spark.sql(\"\"\"\n",
                "    SELECT brand, description, size, classification,\n",
                "           SUM(sales_quantity) AS total_units_sold,\n",
                "           ROUND(SUM(sales_dollars), 2) AS total_revenue,\n",
                "           ROUND(SUM(profit_dollars), 2) AS total_profit_dollars,\n",
                "           ROUND(AVG(margin_pct), 2) AS avg_margin_pct\n",
                "    FROM gold_se\n",
                "    GROUP BY brand, description, size, classification\n",
                "\"\"\")\n",
                "write_gold(product_profitability, \"product_profitability\")\n",
                "\n",
                "brand_profitability = spark.sql(\"\"\"\n",
                "    SELECT brand, FIRST(classification) AS classification,\n",
                "           ROUND(SUM(sales_dollars), 2) AS total_revenue,\n",
                "           ROUND(SUM(profit_dollars), 2) AS total_profit_dollars,\n",
                "           ROUND(AVG(margin_pct), 2) AS avg_margin_pct\n",
                "    FROM gold_se\n",
                "    GROUP BY brand\n",
                "\"\"\")\n",
                "write_gold(brand_profitability, \"brand_profitability\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}