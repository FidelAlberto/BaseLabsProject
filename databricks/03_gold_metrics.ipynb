{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cell-gold-header",
            "metadata": {},
            "source": [
                "# ü•á Gold Layer ‚Äî Business Metrics\n",
                "\n",
                "**Medallion Architecture: Bronze ‚Üí Silver ‚Üí Gold**\n",
                "\n",
                "This notebook produces all analytical tables consumed directly by Power BI.\n",
                "All business logic (profit, margin, rankings, loss detection) is applied here.\n",
                "\n",
                "| Gold Table | Purpose |\n",
                "|---|---|\n",
                "| `gold.sales_enriched` | Row-level sales + cost data with profit & margin |\n",
                "| `gold.product_profitability` | Top/bottom products by profit $ and margin % |\n",
                "| `gold.brand_profitability` | Top/bottom brands by profit $ and margin % |\n",
                "| `gold.loss_makers` | All products/brands with negative cumulative profit |\n",
                "| `gold.sales_by_store` | Revenue, profit, margin by store and city |\n",
                "| `gold.sales_time_series` | Monthly profit and revenue trend |\n",
                "| `gold.inventory_delta` | Ending ‚àí Beginning inventory: over/understocked |\n",
                "| `gold.vendor_performance` | Vendor spend, avg price, implied margin |\n",
                "| `gold.size_analysis` | Profit and margin by bottle/pack size |\n",
                "| `gold.classification_performance` | Profit by spirit classification |\n",
                "\n",
                "**Business Logic:**\n",
                "- `profit_dollars = sales_dollars - (cost_per_unit √ó sales_quantity)`\n",
                "- `margin_pct = profit_dollars / sales_dollars √ó 100`\n",
                "\n",
                "---\n",
                "**Author:** Data Engineering Team  \n",
                "**Last Updated:** 2026-02-24  \n",
                "**Run Order:** 3 of 3 (requires `02_silver_cleaning.ipynb` to have run first)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-config-header",
            "metadata": {},
            "source": [
                "## 0. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-config",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import functions as F\n",
                "from pyspark.sql.window import Window\n",
                "\n",
                "CATALOG       = \"main\"          # ‚Üê UPDATE if using a different Unity Catalog\n",
                "SILVER_SCHEMA = f\"{CATALOG}.silver\"\n",
                "GOLD_SCHEMA   = f\"{CATALOG}.gold\"\n",
                "\n",
                "print(f\"Reading from : {SILVER_SCHEMA}\")\n",
                "print(f\"Writing to   : {GOLD_SCHEMA}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-create-db-header",
            "metadata": {},
            "source": [
                "## 1. Create Gold Schema"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-create-db",
            "metadata": {},
            "outputs": [],
            "source": [
                "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {GOLD_SCHEMA}\")\n",
                "print(f\"‚úÖ  Schema '{GOLD_SCHEMA}' is ready.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-views-header",
            "metadata": {},
            "source": [
                "## 2. Register Silver Tables as Temporary Views"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-views",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Silver tables once, cache where appropriate\n",
                "silver_sales    = spark.table(f\"{SILVER_SCHEMA}.sales\")\n",
                "silver_purchases = spark.table(f\"{SILVER_SCHEMA}.purchases\")\n",
                "silver_beg_inv  = spark.table(f\"{SILVER_SCHEMA}.beg_inventory\")\n",
                "silver_end_inv  = spark.table(f\"{SILVER_SCHEMA}.end_inventory\")\n",
                "\n",
                "silver_sales.createOrReplaceTempView(\"sv_sales\")\n",
                "silver_purchases.createOrReplaceTempView(\"sv_purchases\")\n",
                "silver_beg_inv.createOrReplaceTempView(\"sv_beg_inv\")\n",
                "silver_end_inv.createOrReplaceTempView(\"sv_end_inv\")\n",
                "\n",
                "print(\"‚úÖ  Temporary views registered.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-cost-header",
            "metadata": {},
            "source": [
                "## 3. Core Cost Lookup\n",
                "\n",
                "Build a product-level cost lookup from the Silver purchases table.\n",
                "We take the **median cost_per_unit** per (brand, description) combination\n",
                "to smooth out price fluctuations across individual POs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-cost",
            "metadata": {},
            "outputs": [],
            "source": [
                "cost_lookup = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        brand,\n",
                "        description,\n",
                "        PERCENTILE_APPROX(cost_per_unit, 0.5)  AS median_cost_per_unit,\n",
                "        AVG(cost_per_unit)                       AS avg_cost_per_unit,\n",
                "        MIN(cost_per_unit)                       AS min_cost_per_unit,\n",
                "        MAX(cost_per_unit)                       AS max_cost_per_unit,\n",
                "        COUNT(DISTINCT vendor_number)            AS supplier_count\n",
                "    FROM sv_purchases\n",
                "    WHERE cost_per_unit IS NOT NULL\n",
                "      AND cost_per_unit > 0\n",
                "    GROUP BY brand, description\n",
                "\"\"\")\n",
                "\n",
                "cost_lookup.createOrReplaceTempView(\"cost_lookup\")\n",
                "print(f\"‚úÖ  cost_lookup built: {cost_lookup.count():,} product-level cost records.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-se-header",
            "metadata": {},
            "source": [
                "## 4. Gold ‚Äî Sales Enriched\n",
                "\n",
                "Joins sales with the cost lookup to compute row-level **profit** and **margin**.\n",
                "This is the atomic fact table from which all other Gold tables are derived."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-se",
            "metadata": {},
            "outputs": [],
            "source": [
                "sales_enriched = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        s.store,\n",
                "        s.brand,\n",
                "        s.description,\n",
                "        s.size,\n",
                "        s.classification,\n",
                "        s.sales_date,\n",
                "        s.sale_year,\n",
                "        s.sale_month,\n",
                "        s.sale_month_name,\n",
                "        s.sale_week,\n",
                "        s.sales_quantity,\n",
                "        s.sales_dollars,\n",
                "        s.sales_price,\n",
                "        s.excise_tax,\n",
                "        s.volume,\n",
                "        -- Cost resolution: prefer median market cost; fall back to sales_price * 0.6 heuristic\n",
                "        COALESCE(c.median_cost_per_unit, s.sales_price * 0.60)           AS cost_per_unit,\n",
                "        CASE\n",
                "            WHEN c.median_cost_per_unit IS NOT NULL THEN 'purchase_data'\n",
                "            ELSE 'heuristic_60pct'\n",
                "        END                                                               AS cost_source,\n",
                "        -- Profit calculation\n",
                "        ROUND(\n",
                "            s.sales_dollars\n",
                "            - (COALESCE(c.median_cost_per_unit, s.sales_price * 0.60) * s.sales_quantity),\n",
                "        2)                                                                AS profit_dollars,\n",
                "        -- Margin calculation (guard against divide-by-zero)\n",
                "        ROUND(\n",
                "            CASE\n",
                "                WHEN s.sales_dollars = 0 THEN NULL\n",
                "                ELSE (\n",
                "                    (s.sales_dollars\n",
                "                     - COALESCE(c.median_cost_per_unit, s.sales_price * 0.60) * s.sales_quantity)\n",
                "                    / s.sales_dollars\n",
                "                ) * 100\n",
                "            END,\n",
                "        2)                                                                AS margin_pct\n",
                "    FROM sv_sales s\n",
                "    LEFT JOIN cost_lookup c\n",
                "        ON s.brand = c.brand\n",
                "       AND s.description = c.description\n",
                "\"\"\")\n",
                "\n",
                "sales_enriched.createOrReplaceTempView(\"gold_se\")\n",
                "\n",
                "(\n",
                "    sales_enriched.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .partitionBy(\"brand\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.sales_enriched\")\n",
                ")\n",
                "print(f\"‚úÖ  gold.sales_enriched: {sales_enriched.count():,} rows\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-pp-header",
            "metadata": {},
            "source": [
                "## 5. Gold ‚Äî Product Profitability\n",
                "\n",
                "Aggregate by `(brand, description, size)` to compute total profit, total revenue,\n",
                "average margin, and rankings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-pp",
            "metadata": {},
            "outputs": [],
            "source": [
                "product_profitability = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        brand,\n",
                "        description,\n",
                "        size,\n",
                "        classification,\n",
                "        COUNT(*)                                    AS transaction_count,\n",
                "        SUM(sales_quantity)                         AS total_units_sold,\n",
                "        ROUND(SUM(sales_dollars), 2)                AS total_revenue,\n",
                "        ROUND(SUM(profit_dollars), 2)               AS total_profit_dollars,\n",
                "        ROUND(AVG(margin_pct), 2)                   AS avg_margin_pct,\n",
                "        ROUND(MIN(margin_pct), 2)                   AS min_margin_pct,\n",
                "        ROUND(MAX(margin_pct), 2)                   AS max_margin_pct,\n",
                "        ROUND(SUM(cost_per_unit * sales_quantity), 2) AS total_cost,\n",
                "        ROUND(SUM(volume), 2)                       AS total_volume_liters,\n",
                "        -- Ranking columns (populated by window functions below)\n",
                "        0                                           AS rank_by_profit,\n",
                "        0                                           AS rank_by_margin,\n",
                "        CASE WHEN SUM(profit_dollars) < 0 THEN true ELSE false END AS is_loss_maker\n",
                "    FROM gold_se\n",
                "    GROUP BY brand, description, size, classification\n",
                "\"\"\")\n",
                "\n",
                "# Apply proper window rankings using PySpark\n",
                "profit_window = Window.orderBy(F.col(\"total_profit_dollars\").desc())\n",
                "margin_window = Window.orderBy(F.col(\"avg_margin_pct\").desc())\n",
                "\n",
                "product_profitability = (\n",
                "    product_profitability\n",
                "    .drop(\"rank_by_profit\", \"rank_by_margin\")\n",
                "    .withColumn(\"rank_by_profit\", F.rank().over(profit_window))\n",
                "    .withColumn(\"rank_by_margin\", F.rank().over(margin_window))\n",
                ")\n",
                "\n",
                "(\n",
                "    product_profitability.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.product_profitability\")\n",
                ")\n",
                "print(f\"‚úÖ  gold.product_profitability: {product_profitability.count():,} products\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-bp-header",
            "metadata": {},
            "source": [
                "## 6. Gold ‚Äî Brand Profitability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-bp",
            "metadata": {},
            "outputs": [],
            "source": [
                "brand_profitability = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        brand,\n",
                "        -- Most common description for this brand (representative name)\n",
                "        FIRST(description)                           AS sample_description,\n",
                "        FIRST(classification)                        AS classification,\n",
                "        COUNT(DISTINCT description)                  AS sku_count,\n",
                "        COUNT(*)                                     AS transaction_count,\n",
                "        ROUND(SUM(sales_dollars), 2)                 AS total_revenue,\n",
                "        ROUND(SUM(profit_dollars), 2)                AS total_profit_dollars,\n",
                "        ROUND(AVG(margin_pct), 2)                    AS avg_margin_pct,\n",
                "        ROUND(SUM(cost_per_unit * sales_quantity), 2) AS total_cost,\n",
                "        SUM(sales_quantity)                          AS total_units_sold,\n",
                "        ROUND(SUM(volume), 2)                        AS total_volume_liters,\n",
                "        ROUND(SUM(excise_tax), 2)                    AS total_excise_tax,\n",
                "        CASE WHEN SUM(profit_dollars) < 0 THEN true ELSE false END AS is_loss_maker\n",
                "    FROM gold_se\n",
                "    GROUP BY brand\n",
                "\"\"\")\n",
                "\n",
                "brand_profit_window  = Window.orderBy(F.col(\"total_profit_dollars\").desc())\n",
                "brand_margin_window  = Window.orderBy(F.col(\"avg_margin_pct\").desc())\n",
                "\n",
                "brand_profitability = (\n",
                "    brand_profitability\n",
                "    .withColumn(\"rank_by_profit\", F.rank().over(brand_profit_window))\n",
                "    .withColumn(\"rank_by_margin\", F.rank().over(brand_margin_window))\n",
                ")\n",
                "\n",
                "(\n",
                "    brand_profitability.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.brand_profitability\")\n",
                ")\n",
                "print(f\"‚úÖ  gold.brand_profitability: {brand_profitability.count():,} brands\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-lm-header",
            "metadata": {},
            "source": [
                "## 7. Gold ‚Äî Loss Makers\n",
                "\n",
                "Products AND brands with **negative cumulative profit** ‚Äî candidates for elimination\n",
                "from Annie's wholesale catalog."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-lm",
            "metadata": {},
            "outputs": [],
            "source": [
                "loss_products = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        'PRODUCT'                                   AS level,\n",
                "        CAST(brand AS STRING)                       AS brand_id,\n",
                "        description,\n",
                "        size,\n",
                "        classification,\n",
                "        ROUND(SUM(sales_dollars), 2)                AS total_revenue,\n",
                "        ROUND(SUM(profit_dollars), 2)               AS total_profit_dollars,\n",
                "        ROUND(AVG(margin_pct), 2)                   AS avg_margin_pct,\n",
                "        SUM(sales_quantity)                         AS total_units_sold,\n",
                "        COUNT(DISTINCT store)                       AS stores_stocking,\n",
                "        'Negative cumulative profit ‚Äî consider dropping' AS recommendation\n",
                "    FROM gold_se\n",
                "    GROUP BY brand, description, size, classification\n",
                "    HAVING SUM(profit_dollars) < 0\n",
                "    ORDER BY SUM(profit_dollars) ASC\n",
                "\"\"\")\n",
                "\n",
                "loss_brands = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        'BRAND'                                     AS level,\n",
                "        CAST(brand AS STRING)                       AS brand_id,\n",
                "        FIRST(description)                          AS description,\n",
                "        'ALL'                                       AS size,\n",
                "        FIRST(classification)                       AS classification,\n",
                "        ROUND(SUM(sales_dollars), 2)                AS total_revenue,\n",
                "        ROUND(SUM(profit_dollars), 2)               AS total_profit_dollars,\n",
                "        ROUND(AVG(margin_pct), 2)                   AS avg_margin_pct,\n",
                "        SUM(sales_quantity)                         AS total_units_sold,\n",
                "        COUNT(DISTINCT store)                       AS stores_stocking,\n",
                "        'Brand-level losses ‚Äî investigate or discontinue' AS recommendation\n",
                "    FROM gold_se\n",
                "    GROUP BY brand\n",
                "    HAVING SUM(profit_dollars) < 0\n",
                "    ORDER BY SUM(profit_dollars) ASC\n",
                "\"\"\")\n",
                "\n",
                "loss_makers = loss_products.union(loss_brands)\n",
                "\n",
                "(\n",
                "    loss_makers.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.loss_makers\")\n",
                ")\n",
                "prod_count  = loss_products.count()\n",
                "brand_count = loss_brands.count()\n",
                "print(f\"‚úÖ  gold.loss_makers: {prod_count} losing products | {brand_count} losing brands\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-store-header",
            "metadata": {},
            "source": [
                "## 8. Gold ‚Äî Sales by Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-store",
            "metadata": {},
            "outputs": [],
            "source": [
                "sales_by_store = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        store,\n",
                "        -- City comes from sales table if available, else inventory\n",
                "        COUNT(DISTINCT brand)                        AS unique_brands,\n",
                "        COUNT(DISTINCT description)                  AS unique_skus,\n",
                "        COUNT(*)                                     AS transaction_count,\n",
                "        ROUND(SUM(sales_dollars), 2)                 AS total_revenue,\n",
                "        ROUND(SUM(profit_dollars), 2)                AS total_profit_dollars,\n",
                "        ROUND(AVG(margin_pct), 2)                    AS avg_margin_pct,\n",
                "        SUM(sales_quantity)                          AS total_units_sold,\n",
                "        ROUND(SUM(volume), 2)                        AS total_volume_liters,\n",
                "        ROUND(SUM(excise_tax), 2)                    AS total_excise_tax,\n",
                "        MIN(sales_date)                              AS first_sale_date,\n",
                "        MAX(sales_date)                              AS last_sale_date\n",
                "    FROM gold_se\n",
                "    GROUP BY store\n",
                "    ORDER BY total_revenue DESC\n",
                "\"\"\")\n",
                "\n",
                "(\n",
                "    sales_by_store.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.sales_by_store\")\n",
                ")\n",
                "print(f\"‚úÖ  gold.sales_by_store: {sales_by_store.count():,} stores\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-ts-header",
            "metadata": {},
            "source": [
                "## 9. Gold ‚Äî Sales Time Series (Monthly)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-ts",
            "metadata": {},
            "outputs": [],
            "source": [
                "sales_time_series = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        sale_year,\n",
                "        sale_month,\n",
                "        sale_month_name,\n",
                "        ROUND(SUM(sales_dollars), 2)                 AS monthly_revenue,\n",
                "        ROUND(SUM(profit_dollars), 2)                AS monthly_profit,\n",
                "        ROUND(AVG(margin_pct), 2)                    AS avg_margin_pct,\n",
                "        SUM(sales_quantity)                          AS total_units_sold,\n",
                "        COUNT(DISTINCT brand)                        AS active_brands,\n",
                "        COUNT(DISTINCT store)                        AS active_stores,\n",
                "        COUNT(*)                                     AS transaction_count,\n",
                "        ROUND(SUM(volume), 2)                        AS total_volume_liters\n",
                "    FROM gold_se\n",
                "    GROUP BY sale_year, sale_month, sale_month_name\n",
                "    ORDER BY sale_year, sale_month\n",
                "\"\"\")\n",
                "\n",
                "(\n",
                "    sales_time_series.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.sales_time_series\")\n",
                ")\n",
                "print(f\"‚úÖ  gold.sales_time_series: {sales_time_series.count()} monthly records\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-inv-header",
            "metadata": {},
            "source": [
                "## 10. Gold ‚Äî Inventory Delta (Beginning vs Ending)\n",
                "\n",
                "Computes the change in on-hand inventory across the year.\n",
                "Flags **overstocked** items (ending > beginning, meaning units didn't move)\n",
                "and **understocked** items (ending < beginning, potential stock-out risk)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-inv",
            "metadata": {},
            "outputs": [],
            "source": [
                "inventory_delta_sql = \"\"\"\n",
                "    SELECT\n",
                "        COALESCE(b.brand, e.brand)                  AS brand,\n",
                "        COALESCE(b.description, e.description)      AS description,\n",
                "        COALESCE(b.size, e.size)                    AS size,\n",
                "        COALESCE(b.vendor_name, e.vendor_name)      AS vendor_name,\n",
                "        b.on_hand                                   AS beg_on_hand,\n",
                "        e.on_hand                                   AS end_on_hand,\n",
                "        COALESCE(e.on_hand, 0) - COALESCE(b.on_hand, 0) AS inventory_change,\n",
                "        b.price                                     AS unit_price,\n",
                "        ROUND((COALESCE(e.on_hand, 0) - COALESCE(b.on_hand, 0)) * COALESCE(b.price, 0), 2)\n",
                "                                                    AS inventory_value_change,\n",
                "        CASE\n",
                "            WHEN COALESCE(e.on_hand, 0) - COALESCE(b.on_hand, 0) > 50 THEN 'OVERSTOCKED'\n",
                "            WHEN COALESCE(e.on_hand, 0) - COALESCE(b.on_hand, 0) < -50 THEN 'DEPLETED'\n",
                "            ELSE 'STABLE'\n",
                "        END                                         AS stock_status\n",
                "    FROM sv_beg_inv b\n",
                "    FULL OUTER JOIN sv_end_inv e\n",
                "        ON b.brand = e.brand\n",
                "       AND b.description = e.description\n",
                "       AND b.size = e.size\n",
                "       AND b.store = e.store\n",
                "\"\"\"\n",
                "\n",
                "inventory_delta = spark.sql(inventory_delta_sql)\n",
                "\n",
                "(\n",
                "    inventory_delta.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.inventory_delta\")\n",
                ")\n",
                "print(f\"‚úÖ  gold.inventory_delta: {inventory_delta.count():,} product-store records\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-vendor-header",
            "metadata": {},
            "source": [
                "## 11. Gold ‚Äî Vendor Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-vendor",
            "metadata": {},
            "outputs": [],
            "source": [
                "vendor_performance = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        p.vendor_number,\n",
                "        p.vendor_name,\n",
                "        COUNT(DISTINCT p.brand)                      AS brands_supplied,\n",
                "        COUNT(DISTINCT p.description)                AS skus_supplied,\n",
                "        ROUND(SUM(p.dollars), 2)                     AS total_purchase_spend,\n",
                "        SUM(p.quantity)                              AS total_units_purchased,\n",
                "        ROUND(AVG(p.cost_per_unit), 4)               AS avg_cost_per_unit,\n",
                "        COUNT(DISTINCT p.po_number)                  AS total_po_count,\n",
                "        MIN(p.receiving_date)                        AS first_delivery,\n",
                "        MAX(p.receiving_date)                        AS last_delivery,\n",
                "        -- Avg lead time in days (PO date to receiving date)\n",
                "        ROUND(AVG(DATEDIFF(p.receiving_date, p.po_date)), 1) AS avg_lead_time_days\n",
                "    FROM sv_purchases p\n",
                "    GROUP BY p.vendor_number, p.vendor_name\n",
                "    ORDER BY total_purchase_spend DESC\n",
                "\"\"\")\n",
                "\n",
                "(\n",
                "    vendor_performance.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.vendor_performance\")\n",
                ")\n",
                "print(f\"‚úÖ  gold.vendor_performance: {vendor_performance.count():,} vendors\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-size-header",
            "metadata": {},
            "source": [
                "## 12. Gold ‚Äî Size (Package) Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-size",
            "metadata": {},
            "outputs": [],
            "source": [
                "size_analysis = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        size,\n",
                "        COUNT(DISTINCT brand)                        AS unique_brands,\n",
                "        COUNT(DISTINCT description)                  AS unique_skus,\n",
                "        COUNT(*)                                     AS transaction_count,\n",
                "        ROUND(SUM(sales_dollars), 2)                 AS total_revenue,\n",
                "        ROUND(SUM(profit_dollars), 2)                AS total_profit_dollars,\n",
                "        ROUND(AVG(margin_pct), 2)                    AS avg_margin_pct,\n",
                "        SUM(sales_quantity)                          AS total_units_sold,\n",
                "        ROUND(SUM(volume), 2)                        AS total_volume_liters,\n",
                "        ROUND(SUM(sales_dollars) / SUM(sales_quantity), 4) AS avg_selling_price\n",
                "    FROM gold_se\n",
                "    WHERE size IS NOT NULL\n",
                "    GROUP BY size\n",
                "    ORDER BY total_profit_dollars DESC\n",
                "\"\"\")\n",
                "\n",
                "(\n",
                "    size_analysis.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.size_analysis\")\n",
                ")\n",
                "print(f\"‚úÖ  gold.size_analysis: {size_analysis.count()} distinct pack sizes\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-class-header",
            "metadata": {},
            "source": [
                "## 13. Gold ‚Äî Classification (Spirit Type) Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-class",
            "metadata": {},
            "outputs": [],
            "source": [
                "classification_perf = spark.sql(\"\"\"\n",
                "    SELECT\n",
                "        classification,\n",
                "        COUNT(DISTINCT brand)                        AS unique_brands,\n",
                "        COUNT(DISTINCT description)                  AS unique_skus,\n",
                "        COUNT(*)                                     AS transaction_count,\n",
                "        ROUND(SUM(sales_dollars), 2)                 AS total_revenue,\n",
                "        ROUND(SUM(profit_dollars), 2)                AS total_profit_dollars,\n",
                "        ROUND(AVG(margin_pct), 2)                    AS avg_margin_pct,\n",
                "        SUM(sales_quantity)                          AS total_units_sold,\n",
                "        ROUND(SUM(volume), 2)                        AS total_volume_liters,\n",
                "        ROUND(SUM(sales_dollars) / NULLIF(SUM(sales_quantity), 0), 4) AS avg_selling_price,\n",
                "        ROUND(SUM(profit_dollars) / NULLIF(SUM(sales_dollars), 0) * 100, 2)\n",
                "                                                     AS overall_margin_pct\n",
                "    FROM gold_se\n",
                "    WHERE classification IS NOT NULL\n",
                "    GROUP BY classification\n",
                "    ORDER BY total_profit_dollars DESC\n",
                "\"\"\")\n",
                "\n",
                "(\n",
                "    classification_perf.write\n",
                "        .format(\"delta\")\n",
                "        .mode(\"overwrite\")\n",
                "        .option(\"overwriteSchema\", \"true\")\n",
                "        .saveAsTable(f\"{GOLD_SCHEMA}.classification_performance\")\n",
                ")\n",
                "print(f\"‚úÖ  gold.classification_performance: {classification_perf.count()} spirit types\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-val-header",
            "metadata": {},
            "source": [
                "## 14. Final Validation ‚Äî Gold Layer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-gold-val",
            "metadata": {},
            "outputs": [],
            "source": [
                "gold_tables = {\n",
                "    \"sales_enriched\"            : \"profit_dollars\",\n",
                "    \"product_profitability\"     : \"total_profit_dollars\",\n",
                "    \"brand_profitability\"       : \"total_profit_dollars\",\n",
                "    \"loss_makers\"               : \"total_profit_dollars\",\n",
                "    \"sales_by_store\"            : \"total_revenue\",\n",
                "    \"sales_time_series\"         : \"monthly_revenue\",\n",
                "    \"inventory_delta\"           : \"inventory_change\",\n",
                "    \"vendor_performance\"        : \"total_purchase_spend\",\n",
                "    \"size_analysis\"             : \"total_profit_dollars\",\n",
                "    \"classification_performance\": \"total_profit_dollars\",\n",
                "}\n",
                "\n",
                "print(\"\\nüìä  Gold Layer Validation Report\")\n",
                "print(\"=\" * 70)\n",
                "all_passed = True\n",
                "\n",
                "for tbl, key_col in gold_tables.items():\n",
                "    full_name = f\"{GOLD_SCHEMA}.{tbl}\"\n",
                "    df = spark.table(full_name)\n",
                "    count = df.count()\n",
                "    has_col = key_col in df.columns\n",
                "    null_key = df.filter(F.col(key_col).isNull()).count() if has_col else -1\n",
                "    status = \"‚úÖ\" if count > 0 and has_col else \"‚ùå\"\n",
                "    if count == 0 or not has_col:\n",
                "        all_passed = False\n",
                "    print(f\"  {status}  {tbl:<35} | {count:>10,} rows | null '{key_col}': {null_key}\")\n",
                "\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Business sanity checks\n",
                "pp = spark.table(f\"{GOLD_SCHEMA}.product_profitability\")\n",
                "top_product = pp.orderBy(F.col(\"total_profit_dollars\").desc()).first()\n",
                "print(f\"\\n  üèÜ  Top product by profit: Brand={top_product['brand']} | {top_product['description']} | ${top_product['total_profit_dollars']:,.2f}\")\n",
                "\n",
                "bp = spark.table(f\"{GOLD_SCHEMA}.brand_profitability\")\n",
                "top_brand = bp.orderBy(F.col(\"total_profit_dollars\").desc()).first()\n",
                "print(f\"  üèÜ  Top brand  by profit: Brand={top_brand['brand']} | ${top_brand['total_profit_dollars']:,.2f}\")\n",
                "\n",
                "lm = spark.table(f\"{GOLD_SCHEMA}.loss_makers\")\n",
                "positive_losses = lm.filter(F.col(\"total_profit_dollars\") >= 0).count()\n",
                "assert positive_losses == 0, f\"FAILED: {positive_losses} non-negative rows in loss_makers!\"\n",
                "print(f\"  ‚úÖ  Loss-makers table: all {lm.count()} rows have negative profit (correct).\")\n",
                "\n",
                "ts = spark.table(f\"{GOLD_SCHEMA}.sales_time_series\")\n",
                "month_count = ts.count()\n",
                "print(f\"  ‚úÖ  Time series: {month_count} monthly records (expect 12 for full 2016).\")\n",
                "\n",
                "print(f\"\\n{'‚úÖ  All Gold checks PASSED' if all_passed else '‚ö†Ô∏è  Some checks FAILED ‚Äî review output above'}.\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-gold-complete",
            "metadata": {},
            "source": [
                "## ‚úÖ Gold Layer Complete\n",
                "\n",
                "All 10 analytical Gold tables are ready to be consumed by Power BI.\n",
                "\n",
                "**Recommended Power BI connection:** Databricks Partner Connect ‚Üí Power BI ‚Üí select `gold.*` tables.\n",
                "\n",
                "**Next step:** Refer to `productionization_guide.md` to schedule this pipeline as a Databricks Workflow."
            ]
        }
    ]
}