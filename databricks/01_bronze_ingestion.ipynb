{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83e\udd49 Bronze Layer \u2014 Raw Ingestion\n",
                "\n",
                "**Annie's Magic Numbers Medallion Architecture**\n",
                "\n",
                "This notebook ingests raw CSV files into the Bronze layer in Delta format."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udd10 CELL 0 \u2014 ADLS Gen2 Authentication (Storage Account Key)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 0 \u2014 Azure Data Lake Gen2 Authentication\n",
                "# ============================================================\n",
                "# Configuraci\u00f3n de rendimiento para 8 n\u00facleos\n",
                "spark.conf.set('spark.sql.shuffle.partitions', '8')\n",
                "spark.conf.set('spark.databricks.delta.optimizeWrite.enabled', 'true')\n",
                "spark.conf.set('spark.databricks.delta.autoOptimize.optimizeWrite', 'true')\n",
                "\n",
                "spark.conf.set(\n",
                "    \"fs.azure.account.key.anniedatalake123.dfs.core.windows.net\",\n",
                "    \"<REDACTED_AZURE_STORAGE_KEY>\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udfe6 CELL 1 \u2014 Azure Data Lake Base Paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 1 \u2014 Azure Data Lake Gen2 Base Paths\n",
                "# ============================================================\n",
                "container_name = \"annie-data\"\n",
                "storage_account = \"anniedatalake123\"\n",
                "\n",
                "base_path = f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/\"\n",
                "raw_path = base_path + \"raw/\"\n",
                "bronze_path = base_path + \"bronze/\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udfe6 CELL 2 \u2014 Validate RAW Zone Accessibility"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 2 \u2014 Validate RAW Zone Accessibility\n",
                "# ============================================================\n",
                "dbutils.fs.ls(raw_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udfe6 CELL 3 \u2014 Generic CSV Reader Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 3 \u2014 Generic CSV Reader Function\n",
                "# ============================================================\n",
                "def read_csv(filename):\n",
                "    return (\n",
                "        spark.read\n",
                "             .option(\"header\", True)\n",
                "             .option(\"inferSchema\", True)\n",
                "             .csv(raw_path + filename)\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udfe6 CELL 4 \u2014 Load RAW CSV Files into DataFrames"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 4 \u2014 Load RAW CSV Files into DataFrames\n",
                "# ============================================================\n",
                "sales_df = read_csv(\"SalesFINAL12312016.csv\")\n",
                "purchases_df = read_csv(\"PurchasesFINAL12312016.csv\")\n",
                "prices_df = read_csv(\"2017PurchasePricesDec.csv\")\n",
                "begin_inventory_df = read_csv(\"BegInvFINAL12312016.csv\")\n",
                "end_inventory_df = read_csv(\"EndInvFINAL12312016.csv\")\n",
                "invoices_df = read_csv(\"InvoicePurchases12312016.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udfe6 CELL 5 \u2014 Data Inspection & Schema Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 5 \u2014 Data Inspection & Schema Validation\n",
                "# ============================================================\n",
                "display(sales_df)\n",
                "display(purchases_df)\n",
                "display(prices_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udfe6 CELL 6 \u2014 Bronze Delta Writer Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def write_bronze(df, table_name):\n",
                "    tp = bronze_path + table_name\n",
                "    df.write.format('delta').mode('overwrite').save(tp)\n",
                "    print(f'   \u2705 bronze.{table_name} saved')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udfe6 CELL 7 \u2014 Persist DataFrames to Bronze Layer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tables = [\n",
                "    ('sales', sales_df),\n",
                "    ('purchases', purchases_df),\n",
                "    ('prices', prices_df),\n",
                "    ('begin_inventory', begin_inventory_df),\n",
                "    ('end_inventory', end_inventory_df),\n",
                "    ('invoices', invoices_df)\n",
                "]\n",
                "\n",
                "for name, df in tables:\n",
                "    print(f\"Processing bronze.{name}...\")\n",
                "    # Optimizamos para 8 cores antes de escribir\n",
                "    optimized_df = df.repartition(8).cache()\n",
                "    optimized_df.count()\n",
                "    write_bronze(optimized_df, name)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udfe6 CELL 8 \u2014 Validate Bronze Folder Structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 8 \u2014 Validate Bronze Folder Structure\n",
                "# ============================================================\n",
                "dbutils.fs.ls(bronze_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udfe6 CELL 9 \u2014 Validate Delta Read from Bronze"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CELL 9 \u2014 Validate Delta Read from Bronze\n",
                "# ============================================================\n",
                "sales_bronze_df = (\n",
                "    spark.read\n",
                "         .format(\"delta\")\n",
                "         .load(bronze_path + \"sales\")\n",
                ")\n",
                "\n",
                "display(sales_bronze_df)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
