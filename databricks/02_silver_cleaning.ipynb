{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü•à Silver Layer ‚Äî Cleaning & Enrichment\n",
                "\n",
                "**Annie's Magic Numbers Medallion Architecture**\n",
                "\n",
                "This notebook reads Bronze Delta tables, cleans the data, and writes to the Silver layer."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîê Configuration ‚Äî ADLS Gen2 Authentication"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "spark.conf.set(\n",
                "    \"fs.azure.account.key.anniedatalake123.dfs.core.windows.net\",\n",
                "    \"<PASTE_STORAGE_ACCOUNT_KEY_1_HERE>\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¶ Path Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import functions as F\n",
                "from pyspark.sql.types import DoubleType, IntegerType, LongType, StringType, DateType\n",
                "\n",
                "container_name = \"annie-data\"\n",
                "storage_account = \"anniedatalake123\"\n",
                "\n",
                "base_path = f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/\"\n",
                "bronze_path = base_path + \"bronze/\"\n",
                "silver_path = base_path + \"silver/\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¶ Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def normalize_columns(df):\n",
                "    import re\n",
                "    def to_snake(name):\n",
                "        s1 = re.sub(r'(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
                "        return re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower().strip()\n",
                "\n",
                "    new_cols = {c: to_snake(c) for c in df.columns if not c.startswith(\"_\")}\n",
                "    for old, new in new_cols.items():\n",
                "        if old != new:\n",
                "            df = df.withColumnRenamed(old, new)\n",
                "    return df\n",
                "\n",
                "def write_silver(df, table_name, partition_by=None):\n",
                "    writer = (\n",
                "        df.write\n",
                "          .format(\"delta\")\n",
                "          .mode(\"overwrite\")\n",
                "          .option(\"overwriteSchema\", \"true\")\n",
                "    )\n",
                "    if partition_by:\n",
                "        writer = writer.partitionBy(partition_by)\n",
                "    \n",
                "    target_path = silver_path + table_name\n",
                "    writer.save(target_path)\n",
                "    \n",
                "    count = spark.read.format(\"delta\").load(target_path).count()\n",
                "    print(f\"   ‚úÖ  silver.{table_name} saved to {target_path}  ‚Üí  {count:,} rows\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü•à Silver ‚Äî Beginning Inventory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.beg_inventory ...\")\n",
                "beg_inv_raw = spark.read.format(\"delta\").load(bronze_path + \"begin_inventory\")\n",
                "beg_inv = normalize_columns(beg_inv_raw)\n",
                "\n",
                "beg_inv = (\n",
                "    beg_inv\n",
                "    .withColumn(\"on_hand\",    F.col(\"on_hand\").cast(IntegerType()))\n",
                "    .withColumn(\"price\",      F.col(\"price\").cast(DoubleType()))\n",
                "    .withColumn(\"total_cost\", F.col(\"total_cost\").cast(DoubleType()))\n",
                "    .withColumn(\"start_date\", F.to_date(F.col(\"start_date\"), \"yyyy-MM-dd\"))\n",
                "    .filter(F.col(\"inventory_id\").isNotNull())\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"price\") > 0)\n",
                "    .dropDuplicates([\"inventory_id\"])\n",
                "    .withColumn(\"inventory_value\", F.round(F.col(\"on_hand\") * F.col(\"price\"), 2))\n",
                ")\n",
                "\n",
                "write_silver(beg_inv, \"beg_inventory\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü•à Silver ‚Äî Ending Inventory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.end_inventory ...\")\n",
                "end_inv_raw = spark.read.format(\"delta\").load(bronze_path + \"end_inventory\")\n",
                "end_inv = normalize_columns(end_inv_raw)\n",
                "\n",
                "end_inv = (\n",
                "    end_inv\n",
                "    .withColumn(\"on_hand\",    F.col(\"on_hand\").cast(IntegerType()))\n",
                "    .withColumn(\"price\",      F.col(\"price\").cast(DoubleType()))\n",
                "    .withColumn(\"total_cost\", F.col(\"total_cost\").cast(DoubleType()))\n",
                "    .withColumn(\"end_date\",   F.to_date(F.col(\"end_date\"), \"yyyy-MM-dd\"))\n",
                "    .filter(F.col(\"inventory_id\").isNotNull())\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"price\") > 0)\n",
                "    .dropDuplicates([\"inventory_id\"])\n",
                "    .withColumn(\"inventory_value\", F.round(F.col(\"on_hand\") * F.col(\"price\"), 2))\n",
                ")\n",
                "\n",
                "write_silver(end_inv, \"end_inventory\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü•à Silver ‚Äî Purchase Prices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.purchase_prices ...\")\n",
                "pp_raw = spark.read.format(\"delta\").load(bronze_path + \"prices\")\n",
                "pp = normalize_columns(pp_raw)\n",
                "\n",
                "pp = (\n",
                "    pp\n",
                "    .withColumn(\"price\", F.col(\"price\").cast(DoubleType()))\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"description\").isNotNull())\n",
                "    .filter(F.col(\"price\") > 0)\n",
                "    .withColumn(\"brand\", F.col(\"brand\").cast(IntegerType()))\n",
                "    .dropDuplicates([\"brand\", \"description\"])\n",
                ")\n",
                "\n",
                "write_silver(pp, \"purchase_prices\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü•à Silver ‚Äî Invoice Purchases"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.invoice_purchases ...\")\n",
                "inv_raw = spark.read.format(\"delta\").load(bronze_path + \"invoices\")\n",
                "inv = normalize_columns(inv_raw)\n",
                "\n",
                "inv = (\n",
                "    inv\n",
                "    .withColumn(\"vendor_number\",  F.col(\"vendor_number\").cast(IntegerType()))\n",
                "    .withColumn(\"quantity\",       F.col(\"quantity\").cast(IntegerType()))\n",
                "    .withColumn(\"dollars\",        F.col(\"dollars\").cast(DoubleType()))\n",
                "    .withColumn(\"freight\",        F.col(\"freight\").cast(DoubleType()))\n",
                "    .withColumn(\"invoice_date\",   F.to_date(F.col(\"invoice_date\"), \"MM/dd/yyyy\"))\n",
                "    .withColumn(\"pay_date\",       F.to_date(F.col(\"pay_date\"), \"MM/dd/yyyy\"))\n",
                "    .filter(F.col(\"po_number\").isNotNull())\n",
                "    .dropDuplicates([\"vendor_number\", \"po_number\", \"invoice_date\"])\n",
                ")\n",
                "\n",
                "write_silver(inv, \"invoice_purchases\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü•à Silver ‚Äî Purchases (Enriched)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.purchases ...\")\n",
                "purch_raw = spark.read.format(\"delta\").load(bronze_path + \"purchases\")\n",
                "purch = normalize_columns(purch_raw)\n",
                "\n",
                "purch = (\n",
                "    purch\n",
                "    .withColumn(\"vendor_number\",   F.col(\"vendor_number\").cast(IntegerType()))\n",
                "    .withColumn(\"quantity\",        F.col(\"quantity\").cast(IntegerType()))\n",
                "    .withColumn(\"dollars\",         F.col(\"dollars\").cast(DoubleType()))\n",
                "    .withColumn(\"purchase_price\",  F.col(\"purchase_price\").cast(DoubleType()))\n",
                "    .withColumn(\"brand\",           F.col(\"brand\").cast(IntegerType()))\n",
                "    .withColumn(\"po_date\",         F.to_date(F.col(\"po_date\"), \"MM/dd/yyyy\"))\n",
                "    .withColumn(\"receiving_date\",  F.to_date(F.col(\"receiving_date\"), \"MM/dd/yyyy\"))\n",
                "    .withColumn(\"invoice_date\",    F.to_date(F.col(\"invoice_date\"), \"MM/dd/yyyy\"))\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"quantity\") > 0)\n",
                "    .dropDuplicates([\"vendor_number\", \"po_number\", \"brand\", \"description\", \"receiving_date\"])\n",
                ")\n",
                "\n",
                "pp_silver = spark.read.format(\"delta\").load(silver_path + \"purchase_prices\") \\\n",
                "                 .select(\n",
                "                     F.col(\"brand\").alias(\"ref_brand\"),\n",
                "                     F.col(\"description\").alias(\"ref_description\"),\n",
                "                     F.col(\"price\").alias(\"ref_price\")\n",
                "                 )\n",
                "\n",
                "purch_enriched = (\n",
                "    purch\n",
                "    .join(\n",
                "        pp_silver,\n",
                "        on=[purch[\"brand\"] == pp_silver[\"ref_brand\"],\n",
                "            purch[\"description\"] == pp_silver[\"ref_description\"]],\n",
                "        how=\"left\"\n",
                "    )\n",
                "    .withColumn(\n",
                "        \"cost_per_unit\",\n",
                "        F.round(F.coalesce(F.col(\"ref_price\"), F.col(\"purchase_price\")), 4)\n",
                "    )\n",
                "    .drop(\"ref_brand\", \"ref_description\", \"ref_price\")\n",
                "    .withColumn(\"total_cost\", F.round(F.col(\"cost_per_unit\") * F.col(\"quantity\"), 2))\n",
                ")\n",
                "\n",
                "write_silver(purch_enriched, \"purchases\", partition_by=\"brand\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü•à Silver ‚Äî Sales"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.sales ...\")\n",
                "sales_raw = spark.read.format(\"delta\").load(bronze_path + \"sales\")\n",
                "sales = normalize_columns(sales_raw)\n",
                "\n",
                "sales = (\n",
                "    sales\n",
                "    .withColumn(\"brand\",           F.col(\"brand\").cast(IntegerType()))\n",
                "    .withColumn(\"sales_quantity\",  F.col(\"sales_quantity\").cast(IntegerType()))\n",
                "    .withColumn(\"sales_dollars\",   F.col(\"sales_dollars\").cast(DoubleType()))\n",
                "    .withColumn(\"sales_price\",     F.col(\"sales_price\").cast(DoubleType()))\n",
                "    .withColumn(\"excise_tax\",      F.col(\"excise_tax\").cast(DoubleType()))\n",
                "    .withColumn(\"volume\",          F.col(\"volume\").cast(DoubleType()))\n",
                "    .withColumn(\"sales_date\",      F.to_date(F.col(\"sales_date\"), \"MM/dd/yyyy\"))\n",
                "    .withColumn(\"sale_year\",       F.year(\"sales_date\"))\n",
                "    .withColumn(\"sale_month\",      F.month(\"sales_date\"))\n",
                "    .withColumn(\"sale_month_name\", F.date_format(\"sales_date\", \"MMMM\"))\n",
                "    .withColumn(\"sale_week\",       F.weekofyear(\"sales_date\"))\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"sales_dollars\") > 0)\n",
                "    .filter(F.col(\"sales_quantity\") > 0)\n",
                "    .filter(F.col(\"sales_date\").isNotNull())\n",
                "    .dropDuplicates([\"store\", \"brand\", \"description\", \"sales_date\", \"sales_quantity\", \"sales_dollars\"])\n",
                ")\n",
                "\n",
                "write_silver(sales, \"sales\", partition_by=\"brand\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}