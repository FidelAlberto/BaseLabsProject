{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cell-silver-header",
            "metadata": {},
            "source": [
                "# ðŸ¥ˆ Silver Layer â€” Cleaning & Enrichment\n",
                "\n",
                "**Medallion Architecture: Bronze â†’ Silver â†’ Gold**\n",
                "\n",
                "This notebook reads each Bronze Delta table, applies the following transformations,\n",
                "and writes clean Silver Delta tables:\n",
                "\n",
                "| Step | What happens |\n",
                "|---|---|\n",
                "| Column normalization | Lowercase + underscore column names |\n",
                "| Type casting | Prices â†’ DoubleType, Quantities â†’ IntegerType, Dates â†’ DateType |\n",
                "| Null handling | Drop rows without primary business keys or critical financial fields |\n",
                "| Deduplication | Remove exact duplicates on business key combinations |\n",
                "| Cost enrichment | Join `purchases` with `purchase_prices` to produce `cost_per_unit` |\n",
                "\n",
                "---\n",
                "**Author:** Data Engineering Team  \n",
                "**Last Updated:** 2026-02-24  \n",
                "**Run Order:** 2 of 3 (requires `01_bronze_ingestion.ipynb` to have run first)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-config-header",
            "metadata": {},
            "source": [
                "## 0. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-config",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import functions as F\n",
                "from pyspark.sql.types import (\n",
                "    DoubleType, IntegerType, LongType, StringType, DateType\n",
                ")\n",
                "\n",
                "CATALOG      = \"main\"             # â† UPDATE if using a different Unity Catalog\n",
                "BRONZE_DB    = \"bronze\"\n",
                "SILVER_DB    = \"silver\"\n",
                "\n",
                "BRONZE_SCHEMA = f\"{CATALOG}.{BRONZE_DB}\"\n",
                "SILVER_SCHEMA = f\"{CATALOG}.{SILVER_DB}\"\n",
                "\n",
                "print(f\"Reading from : {BRONZE_SCHEMA}\")\n",
                "print(f\"Writing to   : {SILVER_SCHEMA}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-create-db-header",
            "metadata": {},
            "source": [
                "## 1. Create Silver Database / Schema"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-create-db",
            "metadata": {},
            "outputs": [],
            "source": [
                "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {SILVER_SCHEMA}\")\n",
                "print(f\"âœ…  Schema '{SILVER_SCHEMA}' is ready.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-helpers-header",
            "metadata": {},
            "source": [
                "## 2. Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-helpers",
            "metadata": {},
            "outputs": [],
            "source": [
                "def normalize_columns(df):\n",
                "    \"\"\"\n",
                "    Normalize column names to lowercase with underscores.\n",
                "    e.g.  'SalesQuantity' â†’ 'sales_quantity'\n",
                "    \"\"\"\n",
                "    import re\n",
                "    def to_snake(name):\n",
                "        s1 = re.sub(r'(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
                "        return re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower().strip()\n",
                "\n",
                "    new_cols = {c: to_snake(c) for c in df.columns if not c.startswith(\"_\")}\n",
                "    for old, new in new_cols.items():\n",
                "        if old != new:\n",
                "            df = df.withColumnRenamed(old, new)\n",
                "    return df\n",
                "\n",
                "\n",
                "def write_silver(df, table_name: str, partition_by: str = None) -> None:\n",
                "    \"\"\"Write a cleaned DataFrame to the Silver layer as a Delta table.\"\"\"\n",
                "    full_name = f\"{SILVER_SCHEMA}.{table_name}\"\n",
                "    writer = (\n",
                "        df.write\n",
                "          .format(\"delta\")\n",
                "          .mode(\"overwrite\")\n",
                "          .option(\"overwriteSchema\", \"true\")\n",
                "    )\n",
                "    if partition_by:\n",
                "        writer = writer.partitionBy(partition_by)\n",
                "    writer.saveAsTable(full_name)\n",
                "    count = spark.table(full_name).count()\n",
                "    print(f\"   âœ…  {full_name}  â†’  {count:,} rows\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-beg-inv-header",
            "metadata": {},
            "source": [
                "## 3. Silver â€” Beginning Inventory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-beg-inv",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.beg_inventory ...\")\n",
                "\n",
                "beg_inv_raw = spark.table(f\"{BRONZE_SCHEMA}.beg_inventory\")\n",
                "beg_inv = normalize_columns(beg_inv_raw)\n",
                "\n",
                "beg_inv = (\n",
                "    beg_inv\n",
                "    # Drop metadata columns not needed in Silver\n",
                "    .drop(\"_ingestion_timestamp\", \"_source_file\")\n",
                "\n",
                "    # Cast numeric fields\n",
                "    .withColumn(\"on_hand\",    F.col(\"on_hand\").cast(IntegerType()))\n",
                "    .withColumn(\"price\",      F.col(\"price\").cast(DoubleType()))\n",
                "    .withColumn(\"total_cost\", F.col(\"total_cost\").cast(DoubleType()))\n",
                "\n",
                "    # Parse date\n",
                "    .withColumn(\"start_date\", F.to_date(F.col(\"start_date\"), \"yyyy-MM-dd\"))\n",
                "\n",
                "    # Drop rows missing critical identifiers\n",
                "    .filter(F.col(\"inventory_id\").isNotNull())\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"price\") > 0)\n",
                "\n",
                "    # Deduplicate on primary key\n",
                "    .dropDuplicates([\"inventory_id\"])\n",
                "\n",
                "    # Derived field: cost basis = on-hand qty Ã— purchase price\n",
                "    .withColumn(\"inventory_value\", F.round(F.col(\"on_hand\") * F.col(\"price\"), 2))\n",
                ")\n",
                "\n",
                "write_silver(beg_inv, \"beg_inventory\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-end-inv-header",
            "metadata": {},
            "source": [
                "## 4. Silver â€” Ending Inventory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-end-inv",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.end_inventory ...\")\n",
                "\n",
                "end_inv_raw = spark.table(f\"{BRONZE_SCHEMA}.end_inventory\")\n",
                "end_inv = normalize_columns(end_inv_raw)\n",
                "\n",
                "end_inv = (\n",
                "    end_inv\n",
                "    .drop(\"_ingestion_timestamp\", \"_source_file\")\n",
                "    .withColumn(\"on_hand\",    F.col(\"on_hand\").cast(IntegerType()))\n",
                "    .withColumn(\"price\",      F.col(\"price\").cast(DoubleType()))\n",
                "    .withColumn(\"total_cost\", F.col(\"total_cost\").cast(DoubleType()))\n",
                "    .withColumn(\"end_date\",   F.to_date(F.col(\"end_date\"), \"yyyy-MM-dd\"))\n",
                "    .filter(F.col(\"inventory_id\").isNotNull())\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"price\") > 0)\n",
                "    .dropDuplicates([\"inventory_id\"])\n",
                "    .withColumn(\"inventory_value\", F.round(F.col(\"on_hand\") * F.col(\"price\"), 2))\n",
                ")\n",
                "\n",
                "write_silver(end_inv, \"end_inventory\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-pp-header",
            "metadata": {},
            "source": [
                "## 5. Silver â€” Reference Purchase Prices (2017 Dec)\n",
                "\n",
                "This table provides the **cost basis** used to compute profit per unit sold.\n",
                "It is the most reliable cost reference because it reflects actual wholesale prices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-pp",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.purchase_prices ...\")\n",
                "\n",
                "pp_raw = spark.table(f\"{BRONZE_SCHEMA}.purchase_prices\")\n",
                "pp = normalize_columns(pp_raw)\n",
                "\n",
                "pp = (\n",
                "    pp\n",
                "    .drop(\"_ingestion_timestamp\", \"_source_file\")\n",
                "    .withColumn(\"price\", F.col(\"price\").cast(DoubleType()))\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"description\").isNotNull())\n",
                "    .filter(F.col(\"price\").isNotNull())\n",
                "    .filter(F.col(\"price\") > 0)\n",
                "    # Brand in this file is a numeric ID in raw form; we keep it as-is for joining\n",
                "    .withColumn(\"brand\", F.col(\"brand\").cast(IntegerType()))\n",
                "    .dropDuplicates([\"brand\", \"description\"])\n",
                ")\n",
                "\n",
                "write_silver(pp, \"purchase_prices\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-invoice-header",
            "metadata": {},
            "source": [
                "## 6. Silver â€” Invoice Purchases"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-invoice",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.invoice_purchases ...\")\n",
                "\n",
                "inv_raw = spark.table(f\"{BRONZE_SCHEMA}.invoice_purchases\")\n",
                "inv = normalize_columns(inv_raw)\n",
                "\n",
                "inv = (\n",
                "    inv\n",
                "    .drop(\"_ingestion_timestamp\", \"_source_file\")\n",
                "    .withColumn(\"vendor_number\",  F.col(\"vendor_number\").cast(IntegerType()))\n",
                "    .withColumn(\"quantity\",       F.col(\"quantity\").cast(IntegerType()))\n",
                "    .withColumn(\"dollars\",        F.col(\"dollars\").cast(DoubleType()))\n",
                "    .withColumn(\"freight\",        F.col(\"freight\").cast(DoubleType()))\n",
                "    .withColumn(\"invoice_date\",   F.to_date(F.col(\"invoice_date\"), \"MM/dd/yyyy\"))\n",
                "    .withColumn(\"pay_date\",       F.to_date(F.col(\"pay_date\"), \"MM/dd/yyyy\"))\n",
                "    .filter(F.col(\"po_number\").isNotNull())\n",
                "    .dropDuplicates([\"vendor_number\", \"po_number\", \"invoice_date\"])\n",
                ")\n",
                "\n",
                "write_silver(inv, \"invoice_purchases\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-purchases-header",
            "metadata": {},
            "source": [
                "## 7. Silver â€” Purchases (with cost_per_unit enrichment)\n",
                "\n",
                "The `purchases` table records every purchase order line in 2016.\n",
                "We enrich it by joining with `silver.purchase_prices` (the 2017 Dec price list)\n",
                "to ensure a consistent `cost_per_unit` that reflects the actual wholesale cost.\n",
                "\n",
                "**Fallback**: If no match found in purchase_prices, we use the raw `purchase_price`\n",
                "column already present in the purchases table."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-purchases",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.purchases ...\")\n",
                "\n",
                "purch_raw = spark.table(f\"{BRONZE_SCHEMA}.purchases\")\n",
                "purch = normalize_columns(purch_raw)\n",
                "\n",
                "purch = (\n",
                "    purch\n",
                "    .drop(\"_ingestion_timestamp\", \"_source_file\")\n",
                "    # Cast types\n",
                "    .withColumn(\"vendor_number\",   F.col(\"vendor_number\").cast(IntegerType()))\n",
                "    .withColumn(\"quantity\",        F.col(\"quantity\").cast(IntegerType()))\n",
                "    .withColumn(\"dollars\",         F.col(\"dollars\").cast(DoubleType()))\n",
                "    .withColumn(\"purchase_price\",  F.col(\"purchase_price\").cast(DoubleType()))\n",
                "    .withColumn(\"brand\",           F.col(\"brand\").cast(IntegerType()))\n",
                "    # Parse dates\n",
                "    .withColumn(\"po_date\",         F.to_date(F.col(\"po_date\"), \"MM/dd/yyyy\"))\n",
                "    .withColumn(\"receiving_date\",  F.to_date(F.col(\"receiving_date\"), \"MM/dd/yyyy\"))\n",
                "    .withColumn(\"invoice_date\",    F.to_date(F.col(\"invoice_date\"), \"MM/dd/yyyy\"))\n",
                "    # Drop rows without critical fields\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"description\").isNotNull())\n",
                "    .filter(F.col(\"quantity\") > 0)\n",
                "    .dropDuplicates([\"vendor_number\", \"po_number\", \"brand\", \"description\", \"receiving_date\"])\n",
                ")\n",
                "\n",
                "# ------------------------------------------------------------------\n",
                "# Enrich with reference purchase prices\n",
                "# ------------------------------------------------------------------\n",
                "pp_silver = spark.table(f\"{SILVER_SCHEMA}.purchase_prices\") \\\n",
                "                 .select(\n",
                "                     F.col(\"brand\").alias(\"ref_brand\"),\n",
                "                     F.col(\"description\").alias(\"ref_description\"),\n",
                "                     F.col(\"price\").alias(\"ref_price\")\n",
                "                 )\n",
                "\n",
                "purch_enriched = (\n",
                "    purch\n",
                "    .join(\n",
                "        pp_silver,\n",
                "        on=[purch[\"brand\"] == pp_silver[\"ref_brand\"],\n",
                "            purch[\"description\"] == pp_silver[\"ref_description\"]],\n",
                "        how=\"left\"\n",
                "    )\n",
                "    # cost_per_unit: prefer the reference price; fall back to PO purchase price\n",
                "    .withColumn(\n",
                "        \"cost_per_unit\",\n",
                "        F.round(F.coalesce(F.col(\"ref_price\"), F.col(\"purchase_price\")), 4)\n",
                "    )\n",
                "    .drop(\"ref_brand\", \"ref_description\", \"ref_price\")\n",
                "    # Derived: total line cost\n",
                "    .withColumn(\"total_cost\", F.round(F.col(\"cost_per_unit\") * F.col(\"quantity\"), 2))\n",
                ")\n",
                "\n",
                "write_silver(purch_enriched, \"purchases\", partition_by=\"brand\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-sales-header",
            "metadata": {},
            "source": [
                "## 8. Silver â€” Sales (the main revenue table)\n",
                "\n",
                "The sales table is the largest file (~1.7 GB / millions of rows).\n",
                "We partition it by `brand` to optimize Gold layer aggregations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-sales",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Processing silver.sales  (large file â€” may take several minutes) ...\")\n",
                "\n",
                "sales_raw = spark.table(f\"{BRONZE_SCHEMA}.sales\")\n",
                "sales = normalize_columns(sales_raw)\n",
                "\n",
                "sales = (\n",
                "    sales\n",
                "    .drop(\"_ingestion_timestamp\", \"_source_file\")\n",
                "    # Cast numeric fields\n",
                "    .withColumn(\"brand\",           F.col(\"brand\").cast(IntegerType()))\n",
                "    .withColumn(\"sales_quantity\",  F.col(\"sales_quantity\").cast(IntegerType()))\n",
                "    .withColumn(\"sales_dollars\",   F.col(\"sales_dollars\").cast(DoubleType()))\n",
                "    .withColumn(\"sales_price\",     F.col(\"sales_price\").cast(DoubleType()))\n",
                "    .withColumn(\"excise_tax\",      F.col(\"excise_tax\").cast(DoubleType()))\n",
                "    .withColumn(\"volume\",          F.col(\"volume\").cast(DoubleType()))\n",
                "    # Parse date\n",
                "    .withColumn(\"sales_date\",      F.to_date(F.col(\"sales_date\"), \"MM/dd/yyyy\"))\n",
                "    # Derived time columns for easy time-series analysis in Gold\n",
                "    .withColumn(\"sale_year\",       F.year(\"sales_date\"))\n",
                "    .withColumn(\"sale_month\",      F.month(\"sales_date\"))\n",
                "    .withColumn(\"sale_month_name\", F.date_format(\"sales_date\", \"MMMM\"))\n",
                "    .withColumn(\"sale_week\",       F.weekofyear(\"sales_date\"))\n",
                "    # Quality filters\n",
                "    .filter(F.col(\"brand\").isNotNull())\n",
                "    .filter(F.col(\"sales_dollars\") > 0)\n",
                "    .filter(F.col(\"sales_quantity\") > 0)\n",
                "    .filter(F.col(\"sales_date\").isNotNull())\n",
                "    .dropDuplicates([\"store\", \"brand\", \"description\", \"sales_date\", \"sales_quantity\", \"sales_dollars\"])\n",
                ")\n",
                "\n",
                "write_silver(sales, \"sales\", partition_by=\"brand\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-validation-header",
            "metadata": {},
            "source": [
                "## 9. Validation â€” Silver Layer Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cell-silver-validation",
            "metadata": {},
            "outputs": [],
            "source": [
                "silver_tables = [\n",
                "    \"beg_inventory\",\n",
                "    \"end_inventory\",\n",
                "    \"purchases\",\n",
                "    \"sales\",\n",
                "    \"invoice_purchases\",\n",
                "    \"purchase_prices\",\n",
                "]\n",
                "\n",
                "print(\"\\nðŸ“Š  Silver Layer Validation Report\")\n",
                "print(\"=\" * 65)\n",
                "\n",
                "for tbl in silver_tables:\n",
                "    full_name = f\"{SILVER_SCHEMA}.{tbl}\"\n",
                "    df = spark.table(full_name)\n",
                "    count    = df.count()\n",
                "    nullable = sum(df.filter(F.col(c).isNull()).count() > 0 for c in df.columns[:5])\n",
                "    print(f\"  {tbl:<25} | {count:>12,} rows | null cols (first 5): {nullable}\")\n",
                "\n",
                "print(\"=\" * 65)\n",
                "\n",
                "# Spot-check: cost_per_unit coverage in purchases\n",
                "purch_silver = spark.table(f\"{SILVER_SCHEMA}.purchases\")\n",
                "missing_cost = purch_silver.filter(F.col(\"cost_per_unit\").isNull()).count()\n",
                "total_purch  = purch_silver.count()\n",
                "pct_covered  = 100 * (1 - missing_cost / max(total_purch, 1))\n",
                "print(f\"\\n  cost_per_unit coverage  : {pct_covered:.1f}%  ({total_purch - missing_cost:,} / {total_purch:,} rows)\")\n",
                "\n",
                "print(\"\\nâœ…  Silver layer ready.\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cell-silver-complete",
            "metadata": {},
            "source": [
                "## âœ… Silver Cleaning Complete\n",
                "\n",
                "**Next step:** Run `03_gold_metrics.ipynb` to build all analytical Gold tables."
            ]
        }
    ]
}